{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read file line by line\n",
    "Run query on each line\n",
    "Write result out to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from functools import reduce\n",
    "RESULT_FILE = 'query_results.txt'\n",
    "WORD_FILE_DIR = 'word_files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def file_reader(file):\n",
    "    with open(file) as infile:\n",
    "        for line in infile:\n",
    "            print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_result_to_file(result):\n",
    "    # write to file here.\n",
    "    file = open(RESULT_FILE, 'a')\n",
    "    file.write(result +'\\n')\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_occurrence_in_articles(word):\n",
    "    \"\"\"\n",
    "    Reads in the word file and grabs all the article ids.\n",
    "    Returns all article ids for the word in a list.\n",
    "    \"\"\"\n",
    "    article_ids = open(WORD_FILE_DIR + '/' + word + '.txt', 'r').read().split('\\n')\n",
    "    return article_ids[:len(article_ids)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_common_articles(word_list):\n",
    "    \"\"\"\n",
    "    Takes all words in query are argument and find all articels for each word.\n",
    "    Returns a list of articles where all words intersects.\n",
    "    \"\"\"\n",
    "    article_ids_list = []\n",
    "    for word in word_list:\n",
    "        article_ids_list.append(find_occurrence_in_articles(word))\n",
    "        \n",
    "    \n",
    "    return find_intersection_of_all_article_ids(article_ids_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_intersection_of_all_article_ids(article_ids_list):\n",
    "    \"\"\"\n",
    "    Returns the intersection of all the article ids\n",
    "    \"\"\"\n",
    "    result = reduce(set.intersection, map(set, article_ids_list))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'12', '89'}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = ['coffee', 'cat']\n",
    "find_common_articles(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def query(string, *args):\n",
    "    \"\"\"\n",
    "    Takes a string from the file as first parameter.\n",
    "    The args parameter is the query it self in the format of:\n",
    "    ['cat', [2, 4], 'hat']\n",
    "    \"\"\"\n",
    "    if args is None:\n",
    "        return\n",
    "    \n",
    "    for query in args:\n",
    "        # seperate query into parameters\n",
    "        start_word = query[0]\n",
    "        end_word = query[2]\n",
    "        lower_bound = query[1][0]\n",
    "        upper_bound = query[1][1]\n",
    "        \n",
    "        # build regexs\n",
    "        start_word_regex = r\"\\b\" + re.escape(start_word) + r\"\\b\"\n",
    "        end_word_regex = r\"\\b\" + re.escape(end_word) + r\"\\b\"\n",
    "        \n",
    "        # find substring positions\n",
    "        start_word_pos = re.search(start_word_regex, string)\n",
    "        end_word_pos = re.search(end_word_regex, string)\n",
    "\n",
    "        # calc distance between words\n",
    "        char_between = end_word_pos.start() - start_word_pos.end()\n",
    "\n",
    "        if char_between >= lower_bound and char_between <= upper_bound:\n",
    "            result = string[start_word_pos.start(): end_word_pos.end()]\n",
    "            # write result to file\n",
    "            write_result_to_file(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_string = 'I have a really nice cat in hat at home'\n",
    "test_query = ['cat', [2, 4], 'hat']\n",
    "test_query2 = ['I', [2, 6], 'a']\n",
    "query(test_string, test_query, test_query2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def strip_query_intervals(query):\n",
    "    \"\"\"\n",
    "    Will remove any number of substrings from the string which is surrounded by [ ].\n",
    "    \"\"\"\n",
    "    stripped_version = query\n",
    "    if query.find('[') != -1:\n",
    "        stripped_version = query[0:query.find('[')] + query[query.find(']')+1:len(query)]\n",
    "        return strip_query_intervals(stripped_version)\n",
    "    else:\n",
    "        return stripped_version\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heo wl\n"
     ]
    }
   ],
   "source": [
    "print(strip_query_intervals(\"He[ll]o w[or]l[d]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_unique_article_ids(query):\n",
    "    \"\"\"\n",
    "    Making sure the list of ids only contain every word once so the same word wont be checked twice.\n",
    "    Converting the list to set.\n",
    "    \"\"\"\n",
    "    article_ids = strip_query_intervals(query)\n",
    "    \n",
    "    return set(article_ids)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main_function(query):\n",
    "    \"\"\"\n",
    "    This is the main function. Firstly the query is being stripped for the intervals and chopped into\n",
    "    substrings containing only 1 word each. Then the articles occur in is found and intersected with the other\n",
    "    words articles. Finally the function loops through all the intersected articles to see if the query holds.\n",
    "    \"\"\"\n",
    "    \n",
    "    for word in return_unique_article_ids(query).split():\n",
    "        all_word_article_ids.apped(find_occurrence_in_articles(word))\n",
    "    \n",
    "    common_articles = find_common_articles(all_word_article_ids)\n",
    "    \n",
    "    #Run the query function for each article with the original query: query(article_body,query)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

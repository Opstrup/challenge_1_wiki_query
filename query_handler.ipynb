{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from functools import reduce\n",
    "RESULT_FILE = 'query_results.txt'\n",
    "WORD_FILE_DIR = 'word_files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def file_reader(file):\n",
    "    with open(file) as infile:\n",
    "        for line in infile:\n",
    "            print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_result_to_file(result):\n",
    "    # write to file here.\n",
    "    file = open(RESULT_FILE, 'a')\n",
    "    file.write(result +'\\n')\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_occurrence_in_articles(word):\n",
    "    \"\"\"\n",
    "    Reads in the word file and grabs all the article ids.\n",
    "    Returns all article ids for the word in a list.\n",
    "    If no word found is found None is returned\n",
    "    \"\"\"\n",
    "    try:\n",
    "        article_ids = open(WORD_FILE_DIR + '/' + word + '.txt', 'r').read().split('\\n')\n",
    "        return article_ids[:len(article_ids)-1]\n",
    "    except FileNotFoundError:\n",
    "        print('No file found for word')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_common_articles(word_list):\n",
    "    \"\"\"\n",
    "    Takes all words in query are argument and find all articels for each word.\n",
    "    Returns a list of articles where all words intersects.\n",
    "    \"\"\"\n",
    "    article_ids_list = []\n",
    "    for word in word_list:\n",
    "        occurences = find_occurrence_in_articles(word)\n",
    "        if occurences is not None:\n",
    "            article_ids_list.append(occurences)\n",
    "        \n",
    "    \n",
    "    return find_intersection_of_all_article_ids(article_ids_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_intersection_of_all_article_ids(article_ids_list):\n",
    "    \"\"\"\n",
    "    Returns the intersection of all the article ids\n",
    "    \"\"\"\n",
    "    result = reduce(set.intersection, map(set, article_ids_list))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def query(string, *args):\n",
    "    \"\"\"\n",
    "    Takes a string from the file as first parameter.\n",
    "    The args parameter is the query it self in the format of:\n",
    "    ['cat', [2, 4], 'hat']\n",
    "    \"\"\"\n",
    "    if args is None:\n",
    "        return\n",
    "    \n",
    "    for query in args:\n",
    "        # seperate query into parameters\n",
    "        start_word = query[0]\n",
    "        end_word = query[2]\n",
    "        lower_bound = query[1][0]\n",
    "        upper_bound = query[1][1]\n",
    "        \n",
    "        # build regexs\n",
    "        start_word_regex = r\"\\b\" + re.escape(start_word) + r\"\\b\"\n",
    "        end_word_regex = r\"\\b\" + re.escape(end_word) + r\"\\b\"\n",
    "        \n",
    "        # find substring positions\n",
    "        start_word_pos = re.search(start_word_regex, string)\n",
    "        end_word_pos = re.search(end_word_regex, string)\n",
    "\n",
    "        # calc distance between words\n",
    "        char_between = end_word_pos.start() - start_word_pos.end()\n",
    "\n",
    "        if char_between >= lower_bound and char_between <= upper_bound:\n",
    "            result = string[start_word_pos.start(): end_word_pos.end()]\n",
    "            # write result to file\n",
    "            write_result_to_file(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_string = 'I have a really nice cat in hat at home'\n",
    "test_query = ['cat', [2, 4], 'hat']\n",
    "test_query2 = ['I', [2, 6], 'a']\n",
    "query(test_string, test_query, test_query2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def strip_query_intervals(query):\n",
    "    \"\"\"\n",
    "    Will remove any number of substrings from the string which is surrounded by [ ].\n",
    "    \"\"\"\n",
    "    stripped_version = query\n",
    "    if query.find('[') != -1:\n",
    "        stripped_version = query[0:query.find('[')] + query[query.find(']')+1:len(query)]\n",
    "        return strip_query_intervals(stripped_version)\n",
    "    else:\n",
    "        return stripped_version\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_unique_query_words(query):\n",
    "    \"\"\"\n",
    "    Making sure the list of ids only contain every word once so the same word wont be checked twice.\n",
    "    Converting the list to set.\n",
    "    \"\"\"\n",
    "    query_words = strip_query_intervals(query)\n",
    "\n",
    "    return set(query_words.split())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main_function(query):\n",
    "    \"\"\"\n",
    "    This is the main function. Firstly the query is being stripped for the intervals and chopped into\n",
    "    substrings containing only 1 word each. Then the articles occur in is found and intersected with the other\n",
    "    words articles. Finally the function loops through all the intersected articles to see if the query holds.\n",
    "    \"\"\"\n",
    "    all_word_article_ids = []\n",
    "    \n",
    "    for word in return_unique_query_words(query):\n",
    "        all_word_article_ids.append(find_occurrence_in_articles(word))\n",
    "    \n",
    "    print(all_word_article_ids)\n",
    "    common_article_ids = find_common_articles(all_word_article_ids)\n",
    "    print(common_article_ids)\n",
    "    \n",
    "    #Run the query function for each article with the original query: query(article_body,query)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No file found for word\n",
      "[['89', '12', 'test_xml/Wikipedia-20170926101621', 'test_xml/Wikipedia-20170926101621', 'test_xml/Wikipedia-20170926135213'], None]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "must be str, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-551e89ca08aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cat [2, 4] hat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-16e0b53da4bf>\u001b[0m in \u001b[0;36mmain_function\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_word_article_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mcommon_article_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_common_articles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_word_article_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommon_article_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-64a8ea92e6ca>\u001b[0m in \u001b[0;36mfind_common_articles\u001b[0;34m(word_list)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0marticle_ids_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0moccurences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_occurrence_in_articles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moccurences\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0marticle_ids_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moccurences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-ac80552113d6>\u001b[0m in \u001b[0;36mfind_occurrence_in_articles\u001b[0;34m(word)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \"\"\"\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0marticle_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWORD_FILE_DIR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mword\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marticle_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: must be str, not list"
     ]
    }
   ],
   "source": [
    "main_function('cat [2, 4] hat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'word_files/-f.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-e9e9b67ba390>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mquery_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-16e0b53da4bf>\u001b[0m in \u001b[0;36mmain_function\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreturn_unique_query_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mall_word_article_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfind_occurrence_in_articles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_word_article_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-12bb99df07c6>\u001b[0m in \u001b[0;36mfind_occurrence_in_articles\u001b[0;34m(word)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mReturns\u001b[0m \u001b[0mall\u001b[0m \u001b[0marticle\u001b[0m \u001b[0mids\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \"\"\"\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0marticle_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWORD_FILE_DIR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mword\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marticle_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'word_files/-f.txt'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    query_string = (sys.argv[1])\n",
    "\n",
    "    main_function(query_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
